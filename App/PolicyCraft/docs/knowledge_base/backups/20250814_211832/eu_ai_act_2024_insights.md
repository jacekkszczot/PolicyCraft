# EU AI Act (2024) - Regulatory Framework Insights

## Historic Significance:
- **First Comprehensive AI Legal Framework Worldwide**
- **Entered into Force**: August 1, 2024
- **Full Application**: August 2, 2026 (with phased implementation)
- **Global Impact**: Sets precedent for AI regulation internationally

## Risk-Based Regulatory Approach - 4 Levels:

### 1. Unacceptable Risk (BANNED):
- **Harmful Manipulation & Deception**: AI systems that manipulate human behavior
- **Exploitation of Vulnerabilities**: Targeting vulnerable populations
- **Social Scoring**: Government social credit systems
- **Emotion Recognition**: In workplaces and education institutions
- **Real-time Biometric Identification**: In public spaces for law enforcement
- **Biometric Categorization**: To deduce protected characteristics

### 2. High Risk (STRICT OBLIGATIONS):
- **Education Applications**: AI systems determining access to education, exam scoring
- **Critical Infrastructure**: AI safety components in transport, utilities
- **Employment Systems**: CV-sorting, recruitment, worker management
- **Essential Services**: Credit scoring, loan decisions
- **Law Enforcement**: Evidence evaluation, reliability assessment
- **Justice & Democracy**: Court ruling assistance, democratic process support

#### High-Risk System Requirements:
- **Risk Assessment & Mitigation**: Comprehensive safety evaluations
- **High-Quality Datasets**: Minimize discriminatory outcomes
- **Activity Logging**: Ensure traceability of decisions
- **Detailed Documentation**: Full system information for authorities
- **Human Oversight**: Appropriate human control measures
- **Robustness Standards**: Cybersecurity and accuracy requirements

### 3. Limited Risk (TRANSPARENCY OBLIGATIONS):
- **Disclosure Requirements**: Humans must know they're interacting with AI
- **Generative AI Labeling**: AI-generated content must be identifiable
- **Deepfake Identification**: Clear labeling of synthetic media
- **Public Interest Content**: Special marking for AI-generated public information

### 4. Minimal/No Risk (NO SPECIFIC RULES):
- **AI-Enabled Games**: Video games with AI components
- **Spam Filters**: Basic filtering systems
- **Most Current AI Systems**: Majority of existing AI applications fall here

## Higher Education Specific Implications:

### High-Risk Applications in HE:
- **Automated Exam Scoring**: Systems that determine student grades
- **Admission Decisions**: AI tools affecting educational access
- **Student Performance Prediction**: Systems predicting academic outcomes
- **Plagiarism Detection**: When making definitive academic integrity decisions

### Compliance Requirements for HE:
- **Documentation Standards**: Detailed AI system documentation required
- **Human Oversight Protocols**: Final decisions must involve human judgment
- **Bias Testing**: Regular assessment for discriminatory outcomes
- **Transparency Reports**: Clear information about AI system capabilities/limitations
- **Risk Mitigation Plans**: Strategies to address identified risks

## General-Purpose AI Models (GPAIs):
- **Transparency Requirements**: Copyright compliance, training data disclosure
- **Systemic Risk Assessment**: For highly capable or widely-used models
- **Code of Practice**: EU developing detailed compliance guidelines
- **Effective Date**: August 2, 2025 for GPAI obligations

## Governance Structure:
- **European AI Office**: Central coordination and oversight
- **National Authorities**: Member state implementation and enforcement
- **AI Board**: Strategic guidance and coordination
- **Scientific Panel**: Technical expertise and advisory support
- **Advisory Forum**: Multi-stakeholder input and consultation

## Implementation Timeline:
- **February 2, 2025**: Prohibitions and AI literacy obligations active
- **August 2, 2025**: Governance rules and GPAI obligations effective
- **August 2, 2026**: Full AI Act implementation
- **August 2, 2027**: Extended transition for high-risk systems in regulated products

## PolicyCraft Application Keywords:
- **Risk-based regulation**: Fundamental approach for institutional AI governance
- **Human oversight requirements**: Mandatory human involvement in critical decisions
- **Transparency obligations**: Clear disclosure and documentation standards
- **Educational high-risk systems**: Specific focus on academic decision-making AI
- **Compliance frameworks**: Structured approach to regulatory adherence
- **Bias mitigation**: Required assessment and prevention of discriminatory outcomes
