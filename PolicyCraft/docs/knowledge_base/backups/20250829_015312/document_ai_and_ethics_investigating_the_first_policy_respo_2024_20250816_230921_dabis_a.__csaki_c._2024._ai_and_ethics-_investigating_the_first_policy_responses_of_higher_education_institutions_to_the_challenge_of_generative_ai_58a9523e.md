# AI and ethics: Investigating the first policy responses of higher education institutions to the challenge of generative AI

## Document Information
Humanities and
Social Sciences Communications

## Metadata
- **Author(s)**: Attila Dabis
- **Publication Date**: 2024-01-01
- **Processing Date**: 2025-08-17
- **Quality Score**: 0.69
- **Confidence Level**: low

## Executive Summary
No summary available.

## Quality Assessment
Lower quality document (score: 69.0%). Requires manual review before inclusion.

## Key Insights

### Insight 1
ARTICLE
AI and ethics: Investigating the ﬁrst policy
responses of higher education institutions
to the challenge of generative AI
Attila Dabis
1✉& Csaba Csáki
1
This article addresses the ethical challenges posed by generative artiﬁcial intelligence (AI)
tools in higher education and explores the ﬁrst responses of universities to these challenges
globally

### Insight 2
Drawing on ﬁve key international documents from the UN, EU, and OECD, the study
used content analysis to identify key ethical dimensions related to the use of generative AI in
academia, such as accountability, human oversight, transparency, or inclusiveness

### Insight 3
Empirical
evidence was compiled from 30 leading universities ranked among the top 500 in the
Shanghai Ranking list from May to July 2023, covering those institutions that already had
publicly available responses to these dimensions in the form of policy documents or guide-
lines

### Insight 4
Regarding human
oversight, the typical response identiﬁed by the study involves a blend of preventive mea-
sures (e

### Insight 5
The challenge of transparency induced the good practice of clear communication of AI
use in course syllabi in the ﬁrst university responses examined by this study

### Insight 6
Thus, the research had asked what expectations and
guidelines the ﬁrst policies introduced into existing academic
structures to ensure the informed, transparent, responsible and
ethical use of the new tools of generative AI (henceforth GAI) by
students and teachers

### Insight 7
The research reported here thus addressed
actual answers to the question of what happened at the institu-
tional (policy) level as opposed to what should happen with the
use of AI in classrooms

### Insight 8
Even though it was
not yet a widespread practice to adopt separate, AI-related
guidelines, the research focused on universities that had already
done so quite early

### Insight 9
1 The main sources of this
content analysis are internal documents (such as Codes of Ethics,
Academic Regulations, Codes of Practice and Procedure, Guide-
lines for Students and Teachers or similar policy documents)
from those institutions whose response to the GAI challenge was
publicly accessible

### Insight 10
Through these
sources, the study inductively identiﬁes the primary aspects that
these AI guidelines mention and can be connected to higher
education

### Insight 11
Section 4
presents the analysis of the selected international documents and
establishes a list of key ethical principles relevant in HE contexts
and in parallel presents the analysis of the examples distilled from
the institutional policy documents and guidelines along that
dimension

### Insight 12
(2023), while investigating the practicality of AI in education
in general, also consider ethicality in the context of educational
technology and point out that related debates over the last decade
(pre-ChatGPT, so to say), mostly focused on algorithmic ethics,
i

### Insight 13
At the same time, the use of AI by teachers or,
especially, by students has received less attention (or only under
the scope or traditional human ethics)

### Insight 14
The study by Chan (2023) offers a (general) policy framework for
higher education institutions, although it focuses on one location
and is based on the perceptions of students and teachers

### Insight 15
Mhlanga (2023) presents six factors:
respect for privacy, fairness, and non-discrimination, transparency in
the use of ChatGPT, responsible use of AI (including clarifying its
limitations), ChatGPT is not a substitute for human teachers, and
accuracy of information

## Key Themes
### AI in Education
*Relevance Score: 10.00*

### AI in Higher Education
*Relevance Score: 5.97*

### AI Ethics
*Relevance Score: 4.13*

### AI Ethics and Governance
*Relevance Score: 3.12*

### AI Policy and Governance
*Relevance Score: 2.96*

### Institutional Governance and Policy
*Relevance Score: 2.78*

### GenAI in Learning and Assessment
*Relevance Score: 2.60*

### Student Guidelines
*Relevance Score: 2.60*

### Academic Integrity
*Relevance Score: 2.54*

### Research Ethics in AI
*Relevance Score: 2.24*


## Content-Based Recommendations
1. the use of AI detection platforms in university assessments.
2. employing AI detection tools, but only in a restricted manner to ”evaluate the degree to which AI tools have likely been employed” and not as a source for any punitive measures against students (University of Boston, 2023).
3. imposing a signiﬁcant penalty for low-energy or unreﬂective reuse of material generated by AI tools and assigning zero points for merely reproducing the output from AI platforms.
4. instructors to: ask students to respond to a speciﬁc reading that is very new and thus has a limited online footprint; assign group work to be completed in class, with each member contributing; or ask students to create a ﬁrst draft of an assignment by hand, which could be complemented by a call to explain or justify certain elements of their work (University of Toronto, 2023).
5. a 4-tier system but uses a very different logic based on the practical knowledge one can obtain by using GAI.
6. various methods that instructors can apply on sight, with the same set of tools for all students during their courses, which in itself mitigates the effects of any discrepancies in varying student backgrounds (University of Waterloo, 2023): (a) Give students a prompt during class, and the resulting text and ask them to critique and improve it using track changes; (b) Create two distinct texts and have students explain the ﬂaws of each or combine them in some way using track changes; (c) Test code and documentation accuracy with a peer; or (d) Use ChatGPT to provide a preliminary summary of an issue as a jumping-off point for further research and discussion.
7. the practice of “scaffolding”, which is the process of breaking down a larger assignment into subtasks (Columbia University, 2023).
8. using GAI tools, among others, for the purposes of community development.
9. such community-building activities, whether online or in live groups, kill two birds with one stone.
10. harnessing AI tools’ opportunities to improve education instead of attempting to ban them.

## Integration Details
- **Document ID**: 20250816_230921_Dabis_A.__Csaki_C._2024._AI_and_ethics-_Investigating_the_first_policy_responses_of_higher_education_institutions_to_the_challenge_of_generative_AI_58a9523e
- **Processing Version**: PolicyCraft Literature Processor v1.0
- **Integration Date**: 2025-08-17 23:33:34
- **Auto-Generated**: Yes

---
*This document was processed and integrated into the PolicyCraft knowledge base.*
